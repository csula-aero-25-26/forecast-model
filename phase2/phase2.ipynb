{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8280f938-a17f-48f9-8310-924cd21d9022",
   "metadata": {},
   "source": [
    "# Phase 2: Feature Expansion for F10.7 Forecasting\n",
    "\n",
    "## Objective\n",
    "Evaluate how adding new data inputs affects the accuracy of a 7-day ahead forecast of daily F10.7 values.  \n",
    "We will use a single model (Gradient Boosted Trees) and test step-by-step feature additions.\n",
    "\n",
    "## Approach\n",
    "1. **Baseline Setup**\n",
    "   - Target: Daily F10.7, 7 days ahead\n",
    "   - Validation: Walk-forward validation\n",
    "   - Model: Gradient Boosted Trees (LightGBM)\n",
    "\n",
    "2. **Feature Stages**\n",
    "   - **Stage 0:** Persistence baseline (today’s flux → 7-day ahead)\n",
    "   - **Stage 1:** Lag features (last 27 days)\n",
    "   - **Stage 2:** + Persistence baseline as an input\n",
    "   - **Stage 3:** + Rolling statistics (7-day & 27-day mean/std)\n",
    "   - **Stage 4:** + Sunspot numbers (daily, 7-day & 27-day averages)\n",
    "   - **Stage 5:** + Cycle/rotation indicators (27-day, 11-year harmonics)\n",
    "\n",
    "3. **Evaluation**\n",
    "   - Metrics: MAE, RMSE\n",
    "   - Compare each stage against persistence baseline\n",
    "   - Track whether new features provide consistent improvements across folds\n",
    "\n",
    "## Expected Outcome\n",
    "- Identify which features provide predictive value beyond persistence\n",
    "- Quantify incremental improvements in 7-day F10.7 forecast accuracy\n",
    "- Build a foundation for later exploration of additional inputs (geomagnetic indices, flares, EUV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb2fd33-9535-4568-9ac9-d8439850cf68",
   "metadata": {},
   "source": [
    "# Persistance Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56e3d05f-c231-409e-b1ed-60dba19f4733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline 7-day Persistence MAE: 12.79 sfu\n",
      "Baseline 7-day Persistence RMSE: 23.40 sfu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# The local path to the F10.7 text file from Penticton, B.C., Canada\n",
    "file_path = './datasets/f107.txt'\n",
    "\n",
    "# Declare feature (col) names\n",
    "cols = [\n",
    "    \"fluxdate\", \"fluxtime\", \"fluxjulian\", \"fluxcarrington\",\n",
    "    \"fluxobsflux\", \"fluxadjflux\", \"fluxursi\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(file_path, sep='\\\\s+', comment='#', header=None, names=cols)\n",
    "\n",
    "# Convert date\n",
    "df[\"date\"] = pd.to_datetime(df[\"fluxdate\"], format=\"%Y%m%d\", errors=\"coerce\")\n",
    "\n",
    "# Force numeric conversion (turns strings like \"000130.9\" into 130.9 floats)\n",
    "df[\"fluxadjflux\"] = pd.to_numeric(df[\"fluxadjflux\"], errors=\"coerce\")\n",
    "\n",
    "# Group by date (averaging the 3 daily measurements into one)\n",
    "df = df.groupby(\"date\", as_index=False)[\"fluxadjflux\"].mean()\n",
    "\n",
    "# Make a copy of the dataframe for 7 day prediction\n",
    "data7 = df.copy()\n",
    "\n",
    "# Create the target (label): flux 7 days in the future\n",
    "    # EX: For date JAN 1: X -> JAN 1 Flux ; Y -> JAN 8 Flux\n",
    "data7['target_flux'] = data7['fluxadjflux'].shift(-7)\n",
    "\n",
    "# Add lag features: flux from the past 27 days (For LR)\n",
    "for lag in range(1, 28):  # lag1 through lag27\n",
    "    data7[f\"lag{lag}\"] = data7[\"fluxadjflux\"].shift(lag)\n",
    "\n",
    "# Drop the rows without labels (NaN) (happens because we are shifting the data by 7 days)\n",
    "data7 = data7.dropna()\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Baseline persistence: predict that 7-day ahead flux = today's flux\n",
    "data7[\"baseline_pred\"] = data7[\"fluxadjflux\"]\n",
    "\n",
    "# Evaluate errors\n",
    "mae = mean_absolute_error(data7[\"target_flux\"], data7[\"baseline_pred\"])\n",
    "rmse = np.sqrt(mean_squared_error(data7[\"target_flux\"], data7[\"baseline_pred\"]))\n",
    "\n",
    "print(f\"Baseline 7-day Persistence MAE: {mae:.2f} sfu\")\n",
    "print(f\"Baseline 7-day Persistence RMSE: {rmse:.2f} sfu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c449d7-6c54-4528-8e16-dea27c69fcee",
   "metadata": {},
   "source": [
    "## Stage 1: Historical Data\n",
    "\n",
    "### Objective\n",
    "Evaluate how the number of historical lag features (past days of F10.7) impacts the accuracy of a 7-day ahead forecast.  \n",
    "\n",
    "### Process Overview\n",
    "1. **Data Preparation**\n",
    "   - Source: Daily F10.7 adjusted flux values from `f107.txt` (Penticton, B.C., Canada).\n",
    "   - Preprocessing:\n",
    "     - Converted raw text into daily averages.\n",
    "     - Created a target column (`target_flux`) = flux 7 days ahead.\n",
    "     - Added lag features (`lag1 … lag27`) to represent historical context.\n",
    "   - This ensures each row has today’s flux, yesterday’s flux, … up to 27 days back.\n",
    "\n",
    "2. **Baseline Benchmark**\n",
    "   - Persistence baseline = “7 days ahead = today’s flux”.\n",
    "   - Errors measured using Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE).\n",
    "\n",
    "3. **Modeling Approach**\n",
    "   - Model: Gradient Boosted Trees (LightGBM).\n",
    "   - Validation: Time-aware splits rather than random shuffle.\n",
    "   - Feature sets tested:\n",
    "     - Lag 1 (yesterday only)\n",
    "     - Lags 1–7 (past week)\n",
    "     - Lags 1–27 (one solar rotation)\n",
    "     - Lags 1–54 (two rotations)\n",
    "\n",
    "4. **Cycle-Aware Evaluation**\n",
    "   - To see how results depend on solar activity, we split the dataset into **solar cycles** using NOAA minima:\n",
    "     - Cycle 23 partial (2004–2008)\n",
    "     - Cycle 24 full (2008–2019)\n",
    "     - Cycle 25 partial (2019–present)\n",
    "   - Within each cycle:\n",
    "     - Persistence baseline applied.\n",
    "     - LightGBM trained on the first 80% of that cycle, tested on the last 20%.\n",
    "\n",
    "---\n",
    "\n",
    "## Persistence Baseline Results\n",
    "- **Full dataset (2004–present):**\n",
    "  - MAE ≈ 12.8 sfu\n",
    "  - RMSE ≈ 23.4 sfu  \n",
    "- Persistence is a strong benchmark: it works well in quiet periods but fails on sudden solar spikes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efccafc6-930c-4db1-8585-9b50ac8c4ee8",
   "metadata": {},
   "source": [
    "## Extract Solar Cycles\n",
    "\n",
    "To properly evaluate performance across different phases of solar activity, we aligned our dataset \n",
    "with official solar cycle boundaries.  \n",
    "\n",
    "### Process\n",
    "- Downloaded NOAA/NASA dataset: *\"Minima and Maxima of Sunspot Number Cycles\"*  \n",
    "  ([NGDC](https://www.ngdc.noaa.gov/stp/space-weather/solar-data/solar-indices/sunspot-numbers/cycle-data/table_cycle-dates_maximum-minimum.txt))  \n",
    "- Parsed **cycle minima** (start dates) from the text file.\n",
    "- Identified the cycles overlapping our dataset:\n",
    "  - **Cycle 23 minimum**: ~1996 (dataset covers only 2004–2008, partial cycle)\n",
    "  - **Cycle 24 minimum**: ~2008 (full coverage in dataset)\n",
    "  - **Cycle 25 minimum**: ~2019 (dataset covers 2019–present, partial cycle)\n",
    "\n",
    "### Why\n",
    "- F10.7 behavior differs strongly between solar minimum, solar maximum, and declining phases.  \n",
    "- Persistence and ML models may perform very differently depending on which phase they are tested in.  \n",
    "- By splitting evaluation by cycle, we avoid “averaging out” behavior across very different solar conditions.\n",
    "\n",
    "---\n",
    "\n",
    "## Cycle-Based Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2952939-e96a-4246-b0c3-a6f8c98765c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cycle  min_year   min_date\n",
      "41   23.0    1996.0 1996-01-01\n",
      "42   24.0    2008.0 2008-01-01\n",
      "2    25.0    2019.0 2019-01-01\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# parse fixed-width file\n",
    "colspecs = [(0,5), (5,13), (13,21), (21,29)]\n",
    "names = [\"cycle\", \"min_year\", \"max_year\", \"next_min_year\"]\n",
    "\n",
    "df_cycles = pd.read_fwf(\"datasets/solar_cycle_minmax.txt\", colspecs=colspecs, names=names)\n",
    "\n",
    "# clean\n",
    "df_cycles = df_cycles[pd.to_numeric(df_cycles[\"cycle\"], errors=\"coerce\").notna()]\n",
    "df_cycles[\"cycle\"] = df_cycles[\"cycle\"].astype(int)\n",
    "df_cycles[\"min_year\"] = pd.to_numeric(df_cycles[\"min_year\"], errors=\"coerce\")\n",
    "\n",
    "# keep cycles 23–24, and manually add cycle 25 start\n",
    "cycles = df_cycles[df_cycles[\"cycle\"].isin([23,24])][[\"cycle\",\"min_year\"]].copy()\n",
    "cycles.loc[len(cycles)] = [25, 2019.0]\n",
    "\n",
    "# convert fractional year (e.g. 2008.9) to datetime\n",
    "def year_fraction_to_date(yf):\n",
    "    year = int(yf)\n",
    "    frac = yf - year\n",
    "    month = int(round(frac * 12)) or 1\n",
    "    return pd.to_datetime(f\"{year}-{month:02d}-01\")\n",
    "\n",
    "cycles[\"min_date\"] = cycles[\"min_year\"].apply(year_fraction_to_date)\n",
    "print(cycles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e71e7f31-ec14-4333-ae1c-359d530e7026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycle 23 (2004-01-01 to 2008-01-01):\n",
      "  Persistence → MAE: 10.51 | RMSE: 23.06\n",
      "  LightGBM(27 lags) → MAE: 5.18 | RMSE: 6.60\n",
      "Cycle 24 (2008-01-01 to 2019-01-01):\n",
      "  Persistence → MAE: 11.30 | RMSE: 20.03\n",
      "  LightGBM(27 lags) → MAE: 5.20 | RMSE: 9.22\n",
      "Cycle 25 (2019-01-01 to 2025-09-11):\n",
      "  Persistence → MAE: 16.29 | RMSE: 28.19\n",
      "  LightGBM(27 lags) → MAE: 31.82 | RMSE: 43.37\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "def evaluate_cycle(df, start_date, end_date, max_lag=27):\n",
    "    # restrict data to the cycle window\n",
    "    cycle_df = df[(df[\"date\"] >= start_date) & (df[\"date\"] < end_date)].copy()\n",
    "    if cycle_df.empty:\n",
    "        return None\n",
    "    \n",
    "    # drop NaNs from shifting\n",
    "    cycle_df = cycle_df.dropna()\n",
    "\n",
    "    # --- Persistence baseline ---\n",
    "    mae_p = mean_absolute_error(cycle_df[\"target_flux\"], cycle_df[\"fluxadjflux\"])\n",
    "    rmse_p = np.sqrt(mean_squared_error(cycle_df[\"target_flux\"], cycle_df[\"fluxadjflux\"]))\n",
    "\n",
    "    # --- LightGBM model ---\n",
    "    features = [f\"lag{i}\" for i in range(1, max_lag+1)]\n",
    "    cycle_df = cycle_df.dropna(subset=features + [\"target_flux\"])\n",
    "    split_idx = int(len(cycle_df) * 0.8)\n",
    "    train, test = cycle_df.iloc[:split_idx], cycle_df.iloc[split_idx:]\n",
    "\n",
    "    model = lgb.LGBMRegressor(\n",
    "        n_estimators=400,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    )\n",
    "    model.fit(train[features], train[\"target_flux\"])\n",
    "    pred = model.predict(test[features])\n",
    "\n",
    "    mae_m = mean_absolute_error(test[\"target_flux\"], pred)\n",
    "    rmse_m = np.sqrt(mean_squared_error(test[\"target_flux\"], pred))\n",
    "\n",
    "    return mae_p, rmse_p, mae_m, rmse_m\n",
    "\n",
    "# --- Run for cycles 23, 24, 25 ---\n",
    "cycles = [\n",
    "    (23, pd.to_datetime(\"2004-01-01\"), pd.to_datetime(\"2008-01-01\")),  # partial since your data starts 2004\n",
    "    (24, pd.to_datetime(\"2008-01-01\"), pd.to_datetime(\"2019-01-01\")),\n",
    "    (25, pd.to_datetime(\"2019-01-01\"), data7[\"date\"].max())\n",
    "]\n",
    "\n",
    "for c, start, end in cycles:\n",
    "    results = evaluate_cycle(data7, start, end, max_lag=27)\n",
    "    if results:\n",
    "        mae_p, rmse_p, mae_m, rmse_m = results\n",
    "        print(f\"Cycle {c} ({start.date()} to {end.date()}):\")\n",
    "        print(f\"  Persistence → MAE: {mae_p:.2f} | RMSE: {rmse_p:.2f}\")\n",
    "        print(f\"  LightGBM(27 lags) → MAE: {mae_m:.2f} | RMSE: {rmse_m:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611b9b48-d770-4e0b-8c75-577afd56f503",
   "metadata": {},
   "source": [
    "## Cycle-Based Evaluation\n",
    "\n",
    "Before testing new input features, we checked how persistence and LightGBM perform across \n",
    "individual solar cycles. Segmenting the dataset this way is important, because solar activity \n",
    "(and thus forecast difficulty) changes dramatically between cycles. Without this segmentation, \n",
    "results averaged across all time periods can hide where models truly work or fail.\n",
    "\n",
    "### Method\n",
    "- Split dataset by solar cycle minima (NOAA/NASA):\n",
    "  - **Cycle 23 (partial):** 2004–2008  \n",
    "  - **Cycle 24 (full):** 2008–2019  \n",
    "  - **Cycle 25 (partial):** 2019–present  \n",
    "- In each cycle:\n",
    "  - **Persistence:** today’s flux as 7-day forecast  \n",
    "  - **LightGBM:** 27 lag features, trained on first 80% of the cycle, tested on the last 20%  \n",
    "\n",
    "### Results\n",
    "- **Cycle 23:** Persistence MAE=10.51 | RMSE=23.06; LightGBM MAE=5.18 | RMSE=6.60  \n",
    "- **Cycle 24:** Persistence MAE=11.30 | RMSE=20.03; LightGBM MAE=5.20 | RMSE=9.22  \n",
    "- **Cycle 25:** Persistence MAE=16.29 | RMSE=28.19; LightGBM MAE=31.82 | RMSE=43.37  \n",
    "\n",
    "### Takeaways\n",
    "- LightGBM clearly outperformed persistence during Cycles 23 and 24.  \n",
    "- In Cycle 25, persistence held up better while LightGBM failed to generalize.  \n",
    "- **Key Insight:** Restricting evaluation by cycle reveals patterns that global averages would miss.  \n",
    "- Going forward, we will focus on **Cycle 24** as the main testbed for testing lag lengths and adding \n",
    "new input features, since it provides a complete cycle where the model is competitive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511baa5f-fbbc-49a8-bf92-f9815ae1c1f8",
   "metadata": {},
   "source": [
    "## Lag Length Testing\n",
    "\n",
    "Now that we know LightGBM performs well during Cycle 24, we use it as our testbed to measure \n",
    "how the number of historical lag features affects forecast accuracy.  \n",
    "\n",
    "### Method\n",
    "- Dataset restricted to **Cycle 24 (2008–2019)**.  \n",
    "- Input features: past daily F10.7 values (`lag1 … lagN`).  \n",
    "- Tested lag lengths:\n",
    "  - **Lag 1** (yesterday only)  \n",
    "  - **Lags 1–7** (past week)  \n",
    "  - **Lags 1–27** (one solar rotation)  \n",
    "  - **Lags 1–54** (two rotations)  \n",
    "- Model: LightGBM regressor.  \n",
    "- Validation: Chronological 80/20 split within Cycle 24.  \n",
    "\n",
    "### Evaluation\n",
    "For each lag configuration we will compute:\n",
    "- **Mean Absolute Error (MAE)**  \n",
    "- **Root Mean Squared Error (RMSE)**  \n",
    "\n",
    "This will show whether more historical memory improves forecasts, and if there’s a point of diminishing returns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4741152d-8ef2-4767-95ef-6b2545b8cc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM (Cycle 24, Lag 1) → MAE: 5.72 sfu | RMSE: 10.45 sfu\n",
      "LightGBM (Cycle 24, Lag 7) → MAE: 5.41 sfu | RMSE: 9.89 sfu\n",
      "LightGBM (Cycle 24, Lag 27) → MAE: 5.20 sfu | RMSE: 9.22 sfu\n",
      "LightGBM (Cycle 24, Lag 54) → MAE: 5.84 sfu | RMSE: 10.54 sfu\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "\n",
    "# extend lag features up to 54\n",
    "for lag in range(28, 55):  # lag28 through lag54\n",
    "    data7[f\"lag{lag}\"] = data7[\"fluxadjflux\"].shift(lag)\n",
    "\n",
    "# rebuild cycle24 with new columns\n",
    "cycle24 = data7[(data7[\"date\"] >= \"2008-01-01\") & (data7[\"date\"] < \"2019-01-01\")].copy()\n",
    "\n",
    "\n",
    "def evaluate_lags_cycle24(df, max_lag):\n",
    "    features = [f\"lag{i}\" for i in range(1, max_lag+1)]\n",
    "    df = df.dropna(subset=features + [\"target_flux\"])\n",
    "\n",
    "    # chronological 80/20 split\n",
    "    split_idx = int(len(df) * 0.8)\n",
    "    train, test = df.iloc[:split_idx], df.iloc[split_idx:]\n",
    "\n",
    "    X_train, y_train = train[features], train[\"target_flux\"]\n",
    "    X_test,  y_test  = test[features],  test[\"target_flux\"]\n",
    "\n",
    "    model = lgb.LGBMRegressor(\n",
    "        n_estimators=400,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
    "    return mae, rmse\n",
    "\n",
    "# run tests for different lag lengths\n",
    "for lag in [1, 7, 27, 54]:\n",
    "    mae, rmse = evaluate_lags_cycle24(cycle24, lag)\n",
    "    print(f\"LightGBM (Cycle 24, Lag {lag}) → MAE: {mae:.2f} sfu | RMSE: {rmse:.2f} sfu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956e24cb-5b23-41e1-87bb-178a4ce793cd",
   "metadata": {},
   "source": [
    "## Lag Length Results (Cycle 24)\n",
    "\n",
    "### Summary\n",
    "We tested different amounts of historical memory to see how lag length affects 7-day forecasts \n",
    "using LightGBM during Cycle 24 (2008–2019).  \n",
    "\n",
    "### Results\n",
    "| Lag Length | MAE (sfu) | RMSE (sfu) |\n",
    "|------------|-----------|------------|\n",
    "| Lag 1 (yesterday)     | 5.72 | 10.45 |\n",
    "| Lags 1–7 (1 week)     | 5.41 | 9.89  |\n",
    "| Lags 1–27 (1 rotation) | **5.20** | **9.22** |\n",
    "| Lags 1–54 (2 rotations) | 5.84 | 10.54 |\n",
    "\n",
    "### Takeaways\n",
    "- **Lag 1**: too little context, higher error.  \n",
    "- **Lags 1–7**: modest improvement by adding a week of history.  \n",
    "- **Lags 1–27**: best performance — one full solar rotation provides the strongest predictive signal.  \n",
    "- **Lags 1–54**: performance worsens — extra lags add noise rather than useful information.  \n",
    "\n",
    "**Conclusion:** One solar rotation (~27 days of history) gives the best balance of context and signal for 7-day F10.7 forecasts.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fed706a-31e2-4460-99dc-c335bd0b959e",
   "metadata": {},
   "source": [
    "## Adding Solar Cycle and Sunspot Features\n",
    "\n",
    "So far we have only used historical F10.7 lags as input. This captures short-term autocorrelation, \n",
    "but fails to generalize well across solar cycles (as seen in Cycle 25). To improve forecasts, we \n",
    "now introduce additional features that provide broader context on solar activity.\n",
    "\n",
    "### Candidate Features\n",
    "- **Sunspot numbers (SSN):**  \n",
    "  Strongly correlated with F10.7 and directly track solar activity. Adding daily SSN and \n",
    "  short rolling averages (7-day, 27-day) can help models anticipate changes in flux.\n",
    "\n",
    "- **Cycle phase indicators:**  \n",
    "  Encode the repeating nature of solar variability.  \n",
    "  - 27-day solar rotation → `sin(2π * day/27)`, `cos(2π * day/27)`  \n",
    "  - 11-year solar cycle → `sin(2π * day/(11*365))`, `cos(2π * day/(11*365))`  \n",
    "\n",
    "### Why This Matters\n",
    "- Persistence and lag-only models are blind to the *state of the solar cycle*.  \n",
    "- By adding sunspot counts and phase indicators, the model gets information about where we are in \n",
    "  the broader solar process, improving stability across different cycles (especially Cycle 25).  \n",
    "\n",
    "### Next Step\n",
    "1. Load daily sunspot numbers (SILSO dataset).  \n",
    "2. Merge with F10.7 by date.  \n",
    "3. Create new features: daily SSN, rolling averages, and cycle phase harmonics.  \n",
    "4. Re-run the Cycle 24 experiments (lags + sunspots) to see if errors improve compared to lags only.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
